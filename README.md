# 🤖 Retrieval-Augmented Generation (RAG) System

## 📌 Overview
This project implements a **Retrieval-Augmented Generation (RAG) system**, combining **retrieval-based NLP techniques** with **LLM-based text generation** to enhance the accuracy and reliability of generated responses to help me study for my Investments exam.

## 🚀 Features
### 📚 Document Retrieval
✅ Uses **LangChain** for integrating retrieval-based document search.
✅ Loads external knowledge sources for **context-aware responses**.
✅ Efficiently indexes and searches documents using **vector embeddings**.

### 🔍 Large Language Model (LLM) Integration
✅ Integrates **Mistral LLM** for response generation.
✅ Uses **Ollama API** with fine-tuned temperature settings.
✅ Enhances responses with **retrieved contextual data**.

### ⚡ System Optimization
✅ Environment variable handling for secure API usage.
✅ **Adaptive temperature control** to balance creativity and accuracy.
✅ **Scalable architecture** for real-world deployments.

## 🛠 Technologies Used
- 🐍 **Python Libraries:** LangChain, Ollama
- 🔍 **Document Retrieval:** Vector Search, Embeddings
- 🤖 **LLM Model:** Mistral LLM via Ollama
- 📓 **Jupyter Notebook:** Interactive testing and fine-tuning
