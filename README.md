# ğŸ¤– Retrieval-Augmented Generation (RAG) System

## ğŸ“Œ Overview
This project implements a **Retrieval-Augmented Generation (RAG) system**, combining **retrieval-based NLP techniques** with **LLM-based text generation** to enhance the accuracy and reliability of generated responses to help me study for my Investments exam.

## ğŸš€ Features
### ğŸ“š Document Retrieval
âœ… Uses **LangChain** for integrating retrieval-based document search.
âœ… Loads external knowledge sources for **context-aware responses**.
âœ… Efficiently indexes and searches documents using **vector embeddings**.

### ğŸ” Large Language Model (LLM) Integration
âœ… Integrates **Mistral LLM** for response generation.
âœ… Uses **Ollama API** with fine-tuned temperature settings.
âœ… Enhances responses with **retrieved contextual data**.

### âš¡ System Optimization
âœ… Environment variable handling for secure API usage.
âœ… **Adaptive temperature control** to balance creativity and accuracy.
âœ… **Scalable architecture** for real-world deployments.

## ğŸ›  Technologies Used
- ğŸ **Python Libraries:** LangChain, Ollama
- ğŸ” **Document Retrieval:** Vector Search, Embeddings
- ğŸ¤– **LLM Model:** Mistral LLM via Ollama
- ğŸ““ **Jupyter Notebook:** Interactive testing and fine-tuning
